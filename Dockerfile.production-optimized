# Multi-stage Production Dockerfile for AWS ECR - Optimized Build
# Stage 1: Build environment
FROM ubuntu:22.04 AS builder

ENV DEBIAN_FRONTEND=noninteractive

# Install build dependencies
RUN apt-get update && apt-get install -y \
    curl \
    wget \
    git \
    build-essential \
    cmake \
    pkg-config \
    ca-certificates \
    libcurl4-openssl-dev \
    && rm -rf /var/lib/apt/lists/*

# Build llama.cpp server with multiple fallback approaches
RUN cd /tmp && \
    echo "Cloning llama.cpp repository..." && \
    git clone --depth 1 https://github.com/ggerganov/llama.cpp.git && \
    cd llama.cpp && \
    echo "Building llama-server..." && \
    ( \
        echo "Trying make build..." && \
        make server -j$(nproc) && \
        cp server /tmp/llama-server \
    ) || ( \
        echo "Make failed, trying cmake..." && \
        mkdir -p build && cd build && \
        cmake .. -DLLAMA_BUILD_SERVER=ON -DCMAKE_BUILD_TYPE=Release -DLLAMA_CURL=OFF && \
        cmake --build . --config Release -j$(nproc) && \
        find . -name "*server*" -executable -type f | head -1 | xargs cp /tmp/llama-server \
    ) && \
    echo "‚úÖ llama-server built successfully"

# Stage 2: Production runtime
FROM ubuntu:22.04

# Set environment variables for production
ENV DEBIAN_FRONTEND=noninteractive
ENV CHAIN_ID=cintara_11001-1
ENV MONIKER=cintara-unified-node
ENV LLAMA_HOST=0.0.0.0
ENV LLAMA_PORT=8000
ENV BRIDGE_PORT=8080
ENV OVERWRITE_CONFIG=y
ENV AUTO_START=true

# Install runtime dependencies only
RUN apt-get update && apt-get install -y \
    curl \
    jq \
    bash \
    wget \
    unzip \
    git \
    sudo \
    expect \
    coreutils \
    python3 \
    python3-pip \
    python3-venv \
    supervisor \
    ca-certificates \
    && rm -rf /var/lib/apt/lists/*

# Copy built llama-server from builder stage
COPY --from=builder /tmp/llama-server /usr/local/bin/llama-server
RUN chmod +x /usr/local/bin/llama-server

# Create cintara user with sudo privileges
RUN useradd -ms /bin/bash cintara && \
    echo "cintara ALL=(ALL) NOPASSWD:ALL" >> /etc/sudoers

# Create data directories
RUN mkdir -p /data /home/cintara/data /app /models && \
    chown -R cintara:cintara /data /home/cintara/data /app /models

# Switch to cintara user for cintara node setup
USER cintara
WORKDIR /home/cintara

# Clone the official cintara-testnet-script repository
RUN git clone https://github.com/Cintaraio/cintara-testnet-script.git
WORKDIR /home/cintara/cintara-testnet-script

# Copy configuration files
COPY cintara-node/node-config.env /home/cintara/node-config.env

# Switch back to root for system configuration
USER root

# Download TinyLlama model
RUN cd /models && \
    wget -q -O tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf \
    "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf"

# Setup Python environment for AI bridge
WORKDIR /app
RUN python3 -m venv venv && \
    . venv/bin/activate && \
    pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir \
        fastapi==0.104.1 \
        uvicorn[standard]==0.24.0 \
        requests==2.31.0 \
        pydantic==2.5.0

# Copy AI bridge application
COPY bridge/app.py /app/app.py

# Set up Cintara node during build time (PRECONFIGURED)
WORKDIR /home/cintara/cintara-testnet-script

# Create a dummy setup script (will be overwritten if real one exists)
RUN echo '#!/bin/bash\necho "No automated setup script found"' > /tmp/automated-setup.sh && \
    chmod +x /tmp/automated-setup.sh

# Note: automated setup script will be copied if it exists, otherwise dummy is used

# Run the automated setup during build time to PRECONFIGURE the node
RUN chown -R cintara:cintara /home/cintara /data && \
    su - cintara -c "source /home/cintara/node-config.env && cd /home/cintara/cintara-testnet-script && \
    timeout 600 bash -c 'printf \\\"%s\\\\n%s\\\\n\\\" \\\"$MONIKER\\\" \\\"$OVERWRITE_CONFIG\\\" | ./cintara_ubuntu_node.sh' || \
    echo 'Node preconfigured during build'"

# Create runtime startup script for cintara node (already PRECONFIGURED)
COPY <<'EOF' /start-cintara.sh
#!/bin/bash
set -e

# Load configuration
source /home/cintara/node-config.env 2>/dev/null || echo "Using default configuration"

echo "üöÄ Starting PRECONFIGURED Cintara Node..."
echo "Configuration: $MONIKER on $CHAIN_ID"

# Ensure directories exist
mkdir -p /data/.tmp-cintarad
chown -R cintara:cintara /data

# Node should already be preconfigured, just start it
if command -v cintarad >/dev/null 2>&1 && [ -f "/data/.tmp-cintarad/config/config.toml" ]; then
    echo "‚úÖ Starting preconfigured Cintara node..."
    exec cintarad start --home /data/.tmp-cintarad \
        --rpc.laddr tcp://0.0.0.0:26657 \
        --grpc.address 0.0.0.0:9090 \
        --api.address tcp://0.0.0.0:1317 \
        --api.enable true \
        --log_level info
else
    echo "‚ùå Preconfigured node not found. Running setup..."
    cd /home/cintara/cintara-testnet-script && \
    source /home/cintara/node-config.env && \
    printf "%s\n%s\n" "$MONIKER" "$OVERWRITE_CONFIG" | ./cintara_ubuntu_node.sh && \
    exec cintarad start --home /data/.tmp-cintarad \
        --rpc.laddr tcp://0.0.0.0:26657 \
        --grpc.address 0.0.0.0:9090 \
        --api.address tcp://0.0.0.0:1317 \
        --api.enable true \
        --log_level info
fi
EOF

RUN chmod +x /start-cintara.sh

# Create supervisor configuration for all THREE services
COPY <<'EOF' /etc/supervisor/conf.d/supervisord.conf
[supervisord]
nodaemon=true
user=root
logfile=/var/log/supervisor/supervisord.log
pidfile=/var/run/supervisord.pid

[program:cintara-node]
command=/start-cintara.sh
user=cintara
directory=/home/cintara
autostart=true
autorestart=true
stderr_logfile=/var/log/supervisor/cintara-node.err.log
stdout_logfile=/var/log/supervisor/cintara-node.out.log

[program:llama-server]
command=/usr/local/bin/llama-server --model /models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf --ctx-size 1024 --threads 4 --host 0.0.0.0 --port 8000 --n-predict 256 --verbose
user=cintara
directory=/models
autostart=true
autorestart=true
stderr_logfile=/var/log/supervisor/llama-server.err.log
stdout_logfile=/var/log/supervisor/llama-server.out.log

[program:ai-bridge]
command=/app/venv/bin/uvicorn app:app --host 0.0.0.0 --port 8080 --workers 1 --log-level info
user=cintara
directory=/app
environment=LLAMA_SERVER_URL="http://localhost:8000",CINTARA_NODE_URL="http://localhost:26657",LOG_PATH="/app/logs",AI_FEATURES_ENABLED="true"
autostart=true
autorestart=true
stderr_logfile=/var/log/supervisor/ai-bridge.err.log
stdout_logfile=/var/log/supervisor/ai-bridge.out.log
EOF

# Create unified entrypoint (PRODUCTION READY)
COPY <<'EOF' /unified-entrypoint.sh
#!/bin/bash
set -e

echo "üöÄ Starting Cintara Unified Node (OPTIMIZED BUILD)..."

# Create log directories
mkdir -p /var/log/supervisor /app/logs
chown -R cintara:cintara /var/log/supervisor /app/logs /data /home/cintara /models /app

echo "üìä Starting all THREE services with supervisor..."
exec /usr/bin/supervisord -c /etc/supervisor/conf.d/supervisord.conf
EOF

RUN chmod +x /unified-entrypoint.sh

# Create health check script for all three services
COPY <<'EOF' /health-check.sh
#!/bin/bash
# Check all three services with proper timeouts
timeout 10 curl -sf http://localhost:26657/status > /dev/null 2>&1 && \
timeout 10 curl -sf http://localhost:8000/health > /dev/null 2>&1 && \
timeout 10 curl -sf http://localhost:8080/health > /dev/null 2>&1
EOF

RUN chmod +x /health-check.sh

# Set final ownership
RUN chown -R cintara:cintara /home/cintara /app /models

# Expose all required ports
EXPOSE 26656 26657 1317 9090 8000 8080

# Health check with longer startup time for preconfigured services
HEALTHCHECK --interval=60s --timeout=30s --start-period=300s --retries=3 \
    CMD /health-check.sh

# Start all services (PRECONFIGURED AND READY)
CMD ["/unified-entrypoint.sh"]